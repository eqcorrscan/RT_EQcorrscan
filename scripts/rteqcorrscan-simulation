#!/usr/bin/env python
"""
Functions to assist in synthesising real-time detection.

This script has 3 main steps:
    1. Generate a TemplateBank (in a real-situation this would just be updated);
    2. Read in an appropriate Tribe
    3. Start the RealTimeTribe
"""
import logging

from obspy import UTCDateTime
from obspy.clients.fdsn import Client

from obsplus import WaveBank

from collections import namedtuple
from concurrent.futures import ProcessPoolExecutor
from functools import partial

from rt_eqcorrscan import TemplateBank, Reactor, read_config
from rt_eqcorrscan.reactor.spin_up import get_inventory
from rt_eqcorrscan.config.config import Config
from rt_eqcorrscan.event_trigger import (
    CatalogListener, magnitude_rate_trigger_func)

Logger = logging.getLogger(__name__)

KNOWN_QUAKES = {
    "eketahuna": "2014p051675",
    "cook-strait": "2013p543824",  # M 6.5 preceeded by two 5.7 and 5.8
}

Region = namedtuple("Region", ["latitude", "longitude", "radius"])


def synthesise_real_time(
    database_starttime: UTCDateTime,
    database_endtime: UTCDateTime,
    database_region: Region,
    detection_starttime: UTCDateTime,
    config: Config,
    detection_runtime: float = 3600.0,
    make_templates: bool = True,
    speed_up: float = 1,
    debug: bool = False,
    query_interval: float = 60,
):
    """
    """
    if debug:
        config.log_level = "DEBUG"
        print("Using the following configuration:\n{0}".format(config))
    config.setup_logging()

    client = config.rt_match_filter.get_client()

    trigger_func = partial(
        magnitude_rate_trigger_func,
        magnitude_threshold=config.reactor.magnitude_threshold,
        rate_threshold=config.reactor.rate_threshold,
        rate_bin=config.reactor.rate_radius,
        minimum_events_in_bin=config.reactor.minimum_events_in_bin)

    template_bank = TemplateBank(
        config.database_manager.event_path,
        event_name_structure=config.database_manager.event_name_structure,
        event_format=config.database_manager.event_format,
        path_structure=config.database_manager.path_structure,
        event_ext=config.database_manager.event_ext,
        executor=None)

    if make_templates:
        Logger.info("Downloading template events")
        catalog = client.get_events(
            starttime=database_starttime, endtime=database_endtime,
            latitude=database_region.latitude, 
            longitude=database_region.longitude,
            maxradius=database_region.radius)
        
        Logger.info("Building template database")
        template_bank.make_templates(
            catalog=catalog, client=client, **config.template)
    tribe = template_bank.get_templates(
        starttime=database_starttime, endtime=database_endtime,
        latitude=database_region.latitude,
        longitude=database_region.longitude,
        maxradius=database_region.radius)
    inventory = get_inventory(
        client=client, tribe=tribe, starttime=detection_starttime,
        location={"latitude": database_region.latitude,
                  "longitude": database_region.longitude},
        duration=detection_runtime / 86400.,
        max_distance=config.rt_match_filter.max_distance,
        n_stations=config.rt_match_filter.n_stations)

    config.plot.update({"offline": True})  # Use to use data time-stamps

    Logger.info("Downloading data")
    wavebank = WaveBank("simulation_wavebank")
    for network in inventory:
        for station in network:
            for channel in station:
                try:
                    st = client.get_waveforms(
                        network=network.code, 
                        station=station.code, 
                        channel=channel.code,
                        location=channel.location_code,
                        starttime=detection_starttime,
                        endtime=detection_starttime + detection_runtime)
                except Exception as e:
                    Logger.error(
                        "Could not download data for "
                        f"{network.code}.{station.code}."
                        f"{channel.location_code}.{channel.code}")
                    Logger.error(e)
                    continue
                wavebank.put_waveforms(st)

    # Set up config to use the wavebank rather than FDSN.
    config.streaming.update(
        {"rt_client_url": str(wavebank.bank_path),
         "rt_client_type": "obsplus",
         "starttime": detection_starttime,
         "speed_up": speed_up,
         "query_interval": 1.0})

    catalog_lookup_kwargs = database_region._asdict()
    radius = catalog_lookup_kwargs.pop("radius")
    catalog_lookup_kwargs.update({"maxradius": radius})
    listener = CatalogListener(
        client=client, catalog_lookup_kwargs=catalog_lookup_kwargs,
        template_bank=template_bank, interval=query_interval, keep=86400,
        catalog=None, waveform_client=client)
    listener._speed_up = speed_up
    listener._test_start_step = UTCDateTime.now() - detection_starttime

    reactor = Reactor(
        client=client,
        listener=listener, trigger_func=trigger_func,
        template_database=template_bank, config=config)
    Logger.info("Starting reactor")
    reactor.run()


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--quake", type=str, required=True,
        help="Earthquake to synthesise real-time, either the event-id or a "
             f"known key.\n Known events are: \n{KNOWN_QUAKES}")
    parser.add_argument(
        "--config", "-c", type=str, default=None,
        help="Path to configuration file", required=False)
    parser.add_argument(
        "--db-duration", type=int, default=365,
        help="Number of days to generate the database for prior to the chosen event")
    parser.add_argument(
        "--radius", type=float, default=0.5,
        help="Radius in degrees to build database for")
    parser.add_argument(
        "--client", type=str, required=True,
        help="Client to get data from, must have an FDSN waveform and event service")
    parser.add_argument(
        "--templates-made", action="store_false",
        help="Flag to not make new templates - use if re-running an old DB")
    parser.add_argument(
        "--debug", action="store_true",
        help="Flag to run in debug mode, with lots of output to screen")
    
    args = parser.parse_args()

    try:
        client = Client(args.client.lower())
    except Exception as e:
        Logger.warning(e)
        client = Client(args.client)

    config = read_config(args.config)
    quake_id = KNOWN_QUAKES.get(args.quake, args.quake)
    trigger_event = client.get_events(eventid=quake_id)[0]
    trigger_origin = trigger_event.preferred_origin() or trigger_event.origins[0]

    region = Region(
        latitude=trigger_origin.latitude, longitude=trigger_origin.longitude, 
        radius=args.radius)
    
    synthesise_real_time(
        database_endtime=trigger_origin.time,
        database_starttime=trigger_origin.time - (args.db_duration * 86400),
        database_region=region, detection_starttime=trigger_origin.time,
        config=config, make_templates=args.templates_made,
        debug=args.debug)
